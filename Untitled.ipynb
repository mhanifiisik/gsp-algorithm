{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b398cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\mhanifi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mhanifi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mhanifi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: click in c:\\users\\mhanifi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\mhanifi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mhanifi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficient-apriori in c:\\users\\mhanifi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gsppy in c:\\users\\mhanifi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install --user --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint\n",
    "!pip install nltk\n",
    "!pip install efficient-apriori\n",
    "!pip install gsppy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5706d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29a639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mhanifi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import twint\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd89d800",
   "metadata": {},
   "source": [
    "First Dataset #Ukraine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047de944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nc = twint.Config()\\nc.Search=\"ukraine\"  \\nc.Limit = 10000\\nc.Store_csv = True\\nc.Output = \"second.csv\"\\nc.Lang = \"en\"\\nc.Since=\"2022-24-02\"\\ntwint.run.Search(c)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "c = twint.Config()\n",
    "c.Search=\"ukraine\"  \n",
    "c.Limit = 10000\n",
    "c.Store_csv = True\n",
    "c.Output = \"second.csv\"\n",
    "c.Lang = \"en\"\n",
    "c.Since=\"2022-24-02\"\n",
    "twint.run.Search(c)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72376ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9f57bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10003, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eea7241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        üá∫üá¶üá∑üá∫‚ö°Ô∏èThe work of Ka-52 attack helicopters on ...\n",
       "1        Among the landslide of awfulness, the war in U...\n",
       "2        @chillywillers United States sold Poland out t...\n",
       "3        @AndreasStirner @Bildungskind @matthias_sh Wie...\n",
       "4        Bayer also distributed to the media a map of U...\n",
       "                               ...                        \n",
       "9998     Unblocking #Ukraine‚Äôs Ports on the Black Sea f...\n",
       "9999     Pumunta fuck iyong sarili, Putin! (Filipino)  ...\n",
       "10000    @TheNorth212 @ImKnotTheOne Biden has no contro...\n",
       "10001    @KnoxMcM @GRickHall1 @pbtide That‚Äôs incorrect....\n",
       "10002    @briers6 @WiganWarriorsRL Ukraine  lager.good ...\n",
       "Name: tweet, Length: 10003, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c9c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  #needed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c5b669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10003, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8ba740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset =\"tweet\",keep = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0458f9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9927, 36)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb410d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    üá∫üá¶üá∑üá∫‚ö°Ô∏èthe work of ka-52 attack helicopters on ...\n",
       "1    among the landslide of awfulness, the war in u...\n",
       "2    @chillywillers united states sold poland out t...\n",
       "3    @andreasstirner @bildungskind @matthias_sh wie...\n",
       "4    bayer also distributed to the media a map of u...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To lowercase\n",
    "df[\"tweet\"] = df[\"tweet\"].str.lower()\n",
    "df.tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dcae63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing url\n",
    "texts=df.tweet\n",
    "remove_url=lambda x:re.sub(r\"https\\S+\",\"\",str(x))\n",
    "texts_lr=texts.apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f9b18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer(strip_handles=True)\n",
    "texts_lr = texts_lr.apply(lambda row: tknzr.tokenize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84400104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing multiple spaces\n",
    "remove_space=lambda x:re.sub(r'\\s+', ' ', str(x))\n",
    "texts_lr=texts_lr.apply(remove_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d6d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing single words\n",
    "remove_sword=lambda x:re.sub(r'(?:^| )\\w(?:$| )', ' ', str(x))\n",
    "texts_lr=texts_lr.apply(remove_sword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8201452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctions\n",
    "remove_punc=lambda x:re.sub(r'[^\\w\\s]', ' ', str(x))\n",
    "texts_lr=texts_lr.apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45c0a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing special charecters\n",
    "remove_spec=lambda x:re.sub(r'[^\\x00-\\x7f]',r'',str(x)) #removing special charecters\n",
    "texts_lr=texts_lr.apply(remove_spec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52b142ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "remove_words=lambda x: \" \".join([word for word in x.split() if word not in stop_words])\n",
    "texts_lr=texts_lr.apply(remove_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1228ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "remove_emoji(\"Omg another Earthquake üòîüòî\")\n",
    "texts_lr=texts_lr.apply(lambda x : remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b2fd414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing numbers\n",
    "remove_num=lambda x:re.sub(r'[1-9]', ' ', str(x))\n",
    "texts_lr=texts_lr.apply(remove_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f4041ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1530986571050131457</td>\n",
       "      <td>1530986571050131457</td>\n",
       "      <td>2022-05-29 20:56:57 Central European Daylight ...</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>20:56:57</td>\n",
       "      <td>200</td>\n",
       "      <td>882153804</td>\n",
       "      <td>hem_day</td>\n",
       "      <td>hem_day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1530986570483781632</td>\n",
       "      <td>1530986570483781632</td>\n",
       "      <td>2022-05-29 20:56:57 Central European Daylight ...</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>20:56:57</td>\n",
       "      <td>200</td>\n",
       "      <td>491451825</td>\n",
       "      <td>mattabbate1</td>\n",
       "      <td>Matt Abbate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1530986570135781383</td>\n",
       "      <td>1530972629066194947</td>\n",
       "      <td>2022-05-29 20:56:57 Central European Daylight ...</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>20:56:57</td>\n",
       "      <td>200</td>\n",
       "      <td>1229845145731858432</td>\n",
       "      <td>mattstirner</td>\n",
       "      <td>Matt üá¨üáßüáµüá±üá∫üá∏üá®üá©</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'chillywillers', 'name': 'Kor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1530986569427034119</td>\n",
       "      <td>1530956011044995072</td>\n",
       "      <td>2022-05-29 20:56:57 Central European Daylight ...</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>20:56:57</td>\n",
       "      <td>200</td>\n",
       "      <td>1234251953485553672</td>\n",
       "      <td>tweetma75731201</td>\n",
       "      <td>Tweetman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'AndreasStirner', 'name': 'An...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1530986567124361217</td>\n",
       "      <td>1530986565362757633</td>\n",
       "      <td>2022-05-29 20:56:56 Central European Daylight ...</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>20:56:56</td>\n",
       "      <td>200</td>\n",
       "      <td>3125318887</td>\n",
       "      <td>obeznn</td>\n",
       "      <td>obeznnüñ§üíô‚ù§Ô∏è</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id  \\\n",
       "0  1530986571050131457  1530986571050131457   \n",
       "1  1530986570483781632  1530986570483781632   \n",
       "2  1530986570135781383  1530972629066194947   \n",
       "3  1530986569427034119  1530956011044995072   \n",
       "4  1530986567124361217  1530986565362757633   \n",
       "\n",
       "                                          created_at        date      time  \\\n",
       "0  2022-05-29 20:56:57 Central European Daylight ...  2022-05-29  20:56:57   \n",
       "1  2022-05-29 20:56:57 Central European Daylight ...  2022-05-29  20:56:57   \n",
       "2  2022-05-29 20:56:57 Central European Daylight ...  2022-05-29  20:56:57   \n",
       "3  2022-05-29 20:56:57 Central European Daylight ...  2022-05-29  20:56:57   \n",
       "4  2022-05-29 20:56:56 Central European Daylight ...  2022-05-29  20:56:56   \n",
       "\n",
       "   timezone              user_id         username           name place  ...  \\\n",
       "0       200            882153804          hem_day        hem_day   NaN  ...   \n",
       "1       200            491451825      mattabbate1    Matt Abbate   NaN  ...   \n",
       "2       200  1229845145731858432      mattstirner  Matt üá¨üáßüáµüá±üá∫üá∏üá®üá©   NaN  ...   \n",
       "3       200  1234251953485553672  tweetma75731201       Tweetman   NaN  ...   \n",
       "4       200           3125318887           obeznn     obeznnüñ§üíô‚ù§Ô∏è   NaN  ...   \n",
       "\n",
       "  geo source user_rt_id user_rt retweet_id  \\\n",
       "0 NaN    NaN        NaN     NaN        NaN   \n",
       "1 NaN    NaN        NaN     NaN        NaN   \n",
       "2 NaN    NaN        NaN     NaN        NaN   \n",
       "3 NaN    NaN        NaN     NaN        NaN   \n",
       "4 NaN    NaN        NaN     NaN        NaN   \n",
       "\n",
       "                                            reply_to  retweet_date  translate  \\\n",
       "0                                                 []           NaN        NaN   \n",
       "1                                                 []           NaN        NaN   \n",
       "2  [{'screen_name': 'chillywillers', 'name': 'Kor...           NaN        NaN   \n",
       "3  [{'screen_name': 'AndreasStirner', 'name': 'An...           NaN        NaN   \n",
       "4                                                 []           NaN        NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet= texts_lr\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2db5f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "df['tweet']=df['tweet'].apply(lambda text: lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0696a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steeming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "  return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "df['tweet']=df['tweet'].apply(lambda text: stem_words(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a9915e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.tokenize import TweetTokenizer\n",
    "#tt = TweetTokenizer()\n",
    "#df['tweet'].apply(tt.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58dfeceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06756d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "regexp=RegexpTokenizer('\\w+')\n",
    "df['tweet']=df['tweet'].apply(regexp.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e965b717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                    [work, ka, attack, helicopt, ukrainian, nazi, posit, donba, ukrain, ukrainewar, ukrainerussiawar, russiaukrainewar, ukrainianwarcrim, natowar, natorussiawar, russianatorwar]\n",
       "1                                                                                                       [among, landslid, aw, war, ukrain, brand, treat, intern, crisi, ukrain, fight, war, x, quantiti, weapon, z, militari, industri, cog, genocid, kojima, sandbox, cross, nascar, sponsorship]\n",
       "2                                                                                                                                                                                                                             [unit, state, sold, poland, russia, ukrain, realpolitik, alway, win]\n",
       "3        [wie, oft, dieser, dumm, vorschlag, hier, wiederholt, wird, wie, wre, e, fr, die, blockad, deutschland, und, frankreich, zum, nato, beitritt, der, ukrain, 00, von, diesen, den, aufbau, der, ukrain, einzufordern, oder, htten, sie, damal, ohn, deutschland, sich, neu, grnden, sollen]\n",
       "4                                                                                                                               [bayer, also, distribut, medium, map, ukrain, land, donat, russia, question, exist, ukrainian, cultur, nation, kyiv, medium, write, indignantli, sourc, rvvoenkor]\n",
       "                                                                                                                                                   ...                                                                                                                                            \n",
       "9998                                                                                                                                                                                                                                          [unblock, ukrain, port, black, sea, russian, blocad]\n",
       "9999                                                                                                                                                                                          [pumunta, fuck, iyong, sarili, putin, filipino, stoprussianaggress, ukrain, putinswar, putinwarcrim]\n",
       "10000                                                                                                                                              [biden, control, china, pursu, aggress, contain, covid, noth, oil, good, suppli, chain, scale, back, dramat, covid, noth, putin, invad, ukrain]\n",
       "10001                                                                                                                                                                                                                                                    [incorrect, peopl, ukrain, probabl, know]\n",
       "10002                                                                                                                                                                                                                                                                   [ukrain, lager, good, lad]\n",
       "Name: tweet, Length: 9927, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9331d654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9851\n"
     ]
    }
   ],
   "source": [
    "t_transaction=[]\n",
    "for i in range(len(df['tweet'])):\n",
    "    try:\n",
    "        word=df['tweet'][i]\n",
    "        t_transaction.append(word)\n",
    "    except:\n",
    "      pass\n",
    "print(len(t_transaction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93001570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit', 'state', 'sold', 'poland', 'russia', 'ukrain', 'realpolitik', 'alway', 'win']\n"
     ]
    }
   ],
   "source": [
    "print(t_transaction[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b87bf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsppy.gsp import GSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "172c3b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= GSP =========\n",
      "GSP: [{('bacon',): 3, ('eggs',): 2, ('apple',): 1, ('soup',): 2, ('banana',): 1}, {('bacon', 'soup'): 1, ('bacon', 'apple'): 1, ('eggs', 'bacon'): 2, ('eggs', 'apple'): 1, ('eggs', 'soup'): 1, ('bacon', 'banana'): 1, ('soup', 'bacon'): 1, ('soup', 'banana'): 1}]\n",
      "========= APRIORI =========\n",
      "{apple, eggs} -> {bacon} (conf: 1.000, supp: 0.333, lift: 1.000, conv: 0.000)\n",
      "{banana, soup} -> {bacon} (conf: 1.000, supp: 0.333, lift: 1.000, conv: 0.000)\n",
      "{eggs, soup} -> {bacon} (conf: 1.000, supp: 0.333, lift: 1.000, conv: 0.000)\n",
      "{apple, bacon} -> {eggs} (conf: 1.000, supp: 0.333, lift: 1.500, conv: 333333333.333)\n",
      "{bacon, banana} -> {soup} (conf: 1.000, supp: 0.333, lift: 1.500, conv: 333333333.333)\n"
     ]
    }
   ],
   "source": [
    "transactions = [['eggs', 'bacon', 'soup'],\n",
    "                ['eggs', 'bacon', 'apple'],\n",
    "                ['soup', 'bacon', 'banana']\n",
    "]\n",
    "# this operation requires hours of computation!!!\n",
    "resultGSP = GSP(transactions).search(0.3)\n",
    "print(\"========= GSP =========\")\n",
    "print(\"GSP: {}\".format(resultGSP))\n",
    "#print(values)\n",
    "from efficient_apriori import apriori\n",
    "itemsets, rules = apriori(transactions, min_support=0.3,  min_confidence=1)\n",
    "print(\"========= APRIORI =========\")\n",
    "\n",
    "rules_rhs = filter(lambda rule: len(rule.lhs) == 2 and len(rule.rhs) == 1, rules)\n",
    "for rule in sorted(rules_rhs, key=lambda rule: rule.lift):\n",
    "  print(rule) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07a54b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= GSP =========\n",
      "GSP: [{('ukrain',): 9401, ('war',): 1331, ('russia',): 1652, ('die',): 1036, ('und',): 626, ('der',): 809, ('russian',): 1024, ('le',): 515, ('de',): 654, ('l',): 517, ('u',): 710, ('putin',): 1025, ('da',): 622, ('0',): 811}, {('der', 'ukrain'): 680, ('die', 'ukrain'): 894, ('putin', 'ukrain'): 656, ('russia', 'ukrain'): 1039, ('russian', 'ukrain'): 652, ('ukrain', 'russia'): 821, ('ukrain', 'ukrain'): 950, ('ukrain', 'war'): 701, ('war', 'ukrain'): 733}]\n",
      "========= APRIORI =========\n",
      "{der, die} -> {ukrain} (conf: 1.000, supp: 0.056, lift: 1.048, conv: 45680641.559)\n"
     ]
    }
   ],
   "source": [
    "##REAL DATASET\n",
    "resultGSP = GSP(t_transaction).search(0.05)\n",
    "print(\"========= GSP =========\")\n",
    "print(\"GSP: {}\".format(resultGSP))\n",
    "\n",
    "\n",
    "print(\"========= APRIORI =========\")\n",
    "\n",
    "from efficient_apriori import apriori\n",
    "itemsets, rules = apriori(t_transaction, min_support=0.05,  min_confidence=1)\n",
    "rules_rhs = filter(lambda rule: len(rule.lhs) == 2 and len(rule.rhs) == 1, rules)\n",
    "for rule in sorted(rules_rhs, key=lambda rule: rule.lift):\n",
    "  print(rule) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2656d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= GSP =========\n",
      "GSP: [{('ukrain',): 49, ('war',): 4, ('ukrainian',): 5, ('weapon',): 3, ('russia',): 10, ('wie',): 3, ('fr',): 4, ('e',): 3, ('die',): 7, ('und',): 5, ('nato',): 3, ('der',): 6, ('sie',): 3, ('sich',): 3, ('also',): 4, ('land',): 3, ('donat',): 3, ('russian',): 8, ('de',): 4, ('en',): 3, ('la',): 3, ('kill',): 3, ('krieg',): 3, ('im',): 3, ('via',): 3, ('man',): 3, ('need',): 5, ('u',): 4, ('say',): 4, ('auf',): 5, ('ein',): 3, ('got',): 3, ('putin',): 6, ('nicht',): 3, ('da',): 4, ('support',): 3, ('send',): 3, ('0',): 4, ('mehr',): 3}, {('0', '0'): 3, ('auf', 'da'): 4, ('auf', 'der'): 3, ('auf', 'die'): 4, ('auf', 'ukrain'): 4, ('der', 'ukrain'): 5, ('die', 'da'): 4, ('die', 'der'): 4, ('die', 'sie'): 3, ('die', 'ukrain'): 6, ('die', 'und'): 4, ('en', 'ukrain'): 3, ('fr', 'die'): 4, ('fr', 'ukrain'): 3, ('mehr', 'und'): 3, ('nicht', 'da'): 3, ('nicht', 'und'): 3, ('putin', 'russia'): 3, ('putin', 'ukrain'): 4, ('russia', 'ukrain'): 7, ('russian', 'ukrain'): 5, ('say', 'ukrain'): 3, ('send', 'ukrain'): 3, ('u', 'ukrain'): 3, ('ukrain', '0'): 4, ('ukrain', 'da'): 4, ('ukrain', 'der'): 4, ('ukrain', 'land'): 3, ('ukrain', 'need'): 4, ('ukrain', 'putin'): 4, ('ukrain', 'russia'): 5, ('ukrain', 'russian'): 4, ('ukrain', 'sie'): 3, ('ukrain', 'ukrain'): 8, ('ukrain', 'ukrainian'): 4, ('ukrain', 'und'): 4, ('ukrain', 'via'): 3, ('ukrain', 'war'): 3, ('ukrain', 'weapon'): 3, ('und', 'mehr'): 3, ('wie', 'die'): 3, ('wie', 'fr'): 3, ('wie', 'ukrain'): 3}, {('auf', 'die', 'da'): 3, ('auf', 'die', 'ukrain'): 4, ('auf', 'die', 'der'): 3, ('auf', 'ukrain', 'da'): 3, ('die', 'der', 'ukrain'): 3, ('die', 'ukrain', 'da'): 3, ('die', 'ukrain', 'sie'): 3, ('die', 'ukrain', 'und'): 3, ('fr', 'die', 'ukrain'): 3, ('ukrain', 'der', 'ukrain'): 3, ('wie', 'die', 'ukrain'): 3, ('wie', 'fr', 'die'): 3, ('wie', 'fr', 'ukrain'): 3}, {('auf', 'die', 'ukrain', 'da'): 3, ('wie', 'fr', 'die', 'ukrain'): 3}]\n",
      "========= APRIORI =========\n",
      "{auf, da} -> {ukrain} (conf: 1.000, supp: 0.080, lift: 1.020, conv: 20000000.000)\n",
      "{auf, der} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{auf, die} -> {ukrain} (conf: 1.000, supp: 0.100, lift: 1.020, conv: 20000000.000)\n",
      "{auf, nicht} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{auf, und} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{da, die} -> {ukrain} (conf: 1.000, supp: 0.080, lift: 1.020, conv: 20000000.000)\n",
      "{da, nicht} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{da, und} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{der, die} -> {ukrain} (conf: 1.000, supp: 0.080, lift: 1.020, conv: 20000000.000)\n",
      "{der, sich} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{der, sie} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{die, ein} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{die, fr} -> {ukrain} (conf: 1.000, supp: 0.080, lift: 1.020, conv: 20000000.000)\n",
      "{die, mehr} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{die, nicht} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{die, sich} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{die, sie} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{die, und} -> {ukrain} (conf: 1.000, supp: 0.100, lift: 1.020, conv: 20000000.000)\n",
      "{die, wie} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{fr, und} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{fr, wie} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{mehr, und} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{nicht, und} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{putin, russia} -> {ukrain} (conf: 1.000, supp: 0.060, lift: 1.020, conv: 20000000.000)\n",
      "{auf, da} -> {die} (conf: 1.000, supp: 0.080, lift: 7.143, conv: 860000000.000)\n",
      "{auf, der} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{auf, nicht} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{auf, ukrain} -> {die} (conf: 1.000, supp: 0.100, lift: 7.143, conv: 860000000.000)\n",
      "{auf, und} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{da, nicht} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{da, ukrain} -> {die} (conf: 1.000, supp: 0.080, lift: 7.143, conv: 860000000.000)\n",
      "{da, und} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{der, sich} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{der, sie} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{ein, ukrain} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{fr, ukrain} -> {die} (conf: 1.000, supp: 0.080, lift: 7.143, conv: 860000000.000)\n",
      "{fr, und} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{fr, wie} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{mehr, ukrain} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{mehr, und} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{nicht, ukrain} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{nicht, und} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{sich, ukrain} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{sie, ukrain} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{ukrain, und} -> {die} (conf: 1.000, supp: 0.100, lift: 7.143, conv: 860000000.000)\n",
      "{ukrain, wie} -> {die} (conf: 1.000, supp: 0.060, lift: 7.143, conv: 860000000.000)\n",
      "{die, sich} -> {der} (conf: 1.000, supp: 0.060, lift: 8.333, conv: 880000000.000)\n",
      "{die, sie} -> {der} (conf: 1.000, supp: 0.060, lift: 8.333, conv: 880000000.000)\n",
      "{sich, ukrain} -> {der} (conf: 1.000, supp: 0.060, lift: 8.333, conv: 880000000.000)\n",
      "{sie, ukrain} -> {der} (conf: 1.000, supp: 0.060, lift: 8.333, conv: 880000000.000)\n",
      "{da, die} -> {auf} (conf: 1.000, supp: 0.080, lift: 10.000, conv: 900000000.000)\n",
      "{da, nicht} -> {auf} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{da, ukrain} -> {auf} (conf: 1.000, supp: 0.080, lift: 10.000, conv: 900000000.000)\n",
      "{da, und} -> {auf} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{die, nicht} -> {auf} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{nicht, ukrain} -> {auf} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{nicht, und} -> {auf} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{auf, nicht} -> {und} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{da, nicht} -> {und} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{die, mehr} -> {und} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{die, nicht} -> {und} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{mehr, ukrain} -> {und} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{nicht, ukrain} -> {und} (conf: 1.000, supp: 0.060, lift: 10.000, conv: 900000000.000)\n",
      "{auf, nicht} -> {da} (conf: 1.000, supp: 0.060, lift: 12.500, conv: 920000000.000)\n",
      "{auf, und} -> {da} (conf: 1.000, supp: 0.060, lift: 12.500, conv: 920000000.000)\n",
      "{die, nicht} -> {da} (conf: 1.000, supp: 0.060, lift: 12.500, conv: 920000000.000)\n",
      "{nicht, ukrain} -> {da} (conf: 1.000, supp: 0.060, lift: 12.500, conv: 920000000.000)\n",
      "{nicht, und} -> {da} (conf: 1.000, supp: 0.060, lift: 12.500, conv: 920000000.000)\n",
      "{die, wie} -> {fr} (conf: 1.000, supp: 0.060, lift: 12.500, conv: 920000000.000)\n",
      "{ukrain, wie} -> {fr} (conf: 1.000, supp: 0.060, lift: 12.500, conv: 920000000.000)\n",
      "{auf, und} -> {nicht} (conf: 1.000, supp: 0.060, lift: 16.667, conv: 940000000.000)\n",
      "{da, und} -> {nicht} (conf: 1.000, supp: 0.060, lift: 16.667, conv: 940000000.000)\n"
     ]
    }
   ],
   "source": [
    "##REAL DATASET\n",
    "resultGSP = GSP(t_transaction[:50]).search(0.05)\n",
    "print(\"========= GSP =========\")\n",
    "print(\"GSP: {}\".format(resultGSP))\n",
    "\n",
    "\n",
    "print(\"========= APRIORI =========\")\n",
    "\n",
    "from efficient_apriori import apriori\n",
    "itemsets, rules = apriori(t_transaction[:50], min_support=0.05,  min_confidence=1)\n",
    "rules_rhs = filter(lambda rule: len(rule.lhs) == 2 and len(rule.rhs) == 1, rules)\n",
    "for rule in sorted(rules_rhs, key=lambda rule: rule.lift):\n",
    "  print(rule) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf76c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef90d5044a76959b325e77e6ab4aec0dfccefc7c742ea2d46c5ea882c20802b0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
